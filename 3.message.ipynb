{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:3078\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:3078\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType,ModelType\n",
    "from camel.configs import ZhipuAIConfig,DeepSeekConfig\n",
    "from camel.agents import ChatAgent\n",
    "from camel.toolkits import FunctionTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.DEEPSEEK,\n",
    "    model_type=ModelType.DEEPSEEK_CHAT,\n",
    "    model_config_dict=DeepSeekConfig().as_dict(),\n",
    "    api_key=\"sk-4c7c5c6bb7374a9fa76c649ab5fdca47\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi CAMEL AI! ðŸ‘‹ It's great to hear about your open-source community dedicated to the study of autonomous and communicative agents. Your work in advancing the field of AI and fostering collaboration is truly inspiring. Keep up the amazing efforts in pushing the boundaries of what's possible with intelligent systems! ðŸš€ðŸ¤–\n"
     ]
    }
   ],
   "source": [
    "# Define system message\n",
    "sys_msg = \"You are a helpful assistant.\"\n",
    "\n",
    "# set agent\n",
    "camel_agent = ChatAgent(\n",
    "    system_message=sys_msg,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "# Set user message\n",
    "user_msg = \"\"\"Say hi to CAMEL AI, one open-source community dedicated to the\n",
    "    study of autonomous and communicative agents.\"\"\"\n",
    "    \n",
    "# Get response information\n",
    "response = camel_agent.step(user_msg)\n",
    "print(response.msgs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.messages import BaseMessage\n",
    "from camel.types import RoleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = BaseMessage(\n",
    "    role_name=\"test_user\",\n",
    "    role_type=RoleType.USER,\n",
    "    content=\"test content\",\n",
    "    meta_dict = {}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseMessage(role_name='test_user', role_type=<RoleType.USER: 'user'>, meta_dict={}, content='test content', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a user message\n",
    "user_message = BaseMessage.make_user_message(\n",
    "    role_name=\"user\",\n",
    "    content=\"test content for user\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseMessage(role_name='user', role_type=<RoleType.USER: 'user'>, meta_dict=None, content='test content for user', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a assistant message\n",
    "assistant_message = BaseMessage.make_assistant_message(\n",
    "    role_name=\"assistant\",\n",
    "    content=\"test content for assistant\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseMessage(role_name='assistant', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict=None, content='test content for assistant', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The method of BaseMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseMessage(role_name='test_user', role_type=<RoleType.USER: 'user'>, meta_dict={}, content='new content', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new instance with updated content\n",
    "new_message = message.create_new_instance(\"new content\")\n",
    "new_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'test content'}\n"
     ]
    }
   ],
   "source": [
    "# Converting to an OpenAIMessage object\n",
    "from camel.types import OpenAIBackendRole\n",
    "openai_message = message.to_openai_message(OpenAIBackendRole.USER)\n",
    "print(openai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'system', 'content': 'test content'}\n"
     ]
    }
   ],
   "source": [
    "# Converting to an OpenAISystemMessage object\n",
    "openai_system_message = message.to_openai_system_message()\n",
    "print(openai_system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'test content'}\n"
     ]
    }
   ],
   "source": [
    "# Converting to an OpenAIUserMessage object\n",
    "openai_user_message = message.to_openai_user_message()\n",
    "print(openai_user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'test content'}\n"
     ]
    }
   ],
   "source": [
    "# Converting to an OpenAIAssistantMessage object\n",
    "openai_assistant_message = message.to_openai_assistant_message()\n",
    "print(openai_assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role_name': 'test_user', 'role_type': 'USER', 'content': 'test content'}\n"
     ]
    }
   ],
   "source": [
    "# Converting to a dictionary\n",
    "message_dict = message.to_dict()\n",
    "print(message_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
